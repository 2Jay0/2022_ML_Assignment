{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "os.path.expanduser = lambda path: './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 60\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_18 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility\n",
    "import random, os\n",
    "os.environ['PYTHONHASHSEED']='0'\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,    inter_op_parallelism_threads=1,\n",
    "                                                               allow_soft_placement=True, device_count = {'CPU': 1}))\n",
    "from tensorflow.python.keras import backend as K\n",
    "K.set_session(sess)\n",
    "\n",
    "\n",
    "\n",
    "kernel_initializer='glorot_uniform'\n",
    "activation_function = 'relu'\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    model1_1 = Sequential()\n",
    "    model1_1.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model1_1.add(Dropout(0.8))\n",
    "    model1_1.add(Dense(512, activation='relu'))\n",
    "    model1_1.add(Dropout(0.8))\n",
    "    model1_1.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model1_1.summary()\n",
    "\n",
    "    model1_1.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_21 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 673,802\n",
      "Trainable params: 671,754\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "    model1_2 = Sequential()\n",
    "    model1_2.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model1_2.add(Dropout(0.8))\n",
    "    model1_2.add(BatchNormalization())\n",
    "    model1_2.add(Dense(512, activation='relu'))\n",
    "    model1_2.add(Dropout(0.8))\n",
    "    model1_2.add(BatchNormalization())\n",
    "    model1_2.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model1_2.summary()\n",
    "\n",
    "    model1_2.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "    model2_1 = Sequential()\n",
    "    model2_1.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model2_1.add(Dropout(0.5))\n",
    "    model2_1.add(Dense(512, activation='relu'))\n",
    "    model2_1.add(Dropout(0.5))\n",
    "    model2_1.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model2_1.summary()\n",
    "\n",
    "    model2_1.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_27 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 673,802\n",
      "Trainable params: 671,754\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "    model2_2 = Sequential()\n",
    "    model2_2.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model2_2.add(Dropout(0.5))\n",
    "    model2_2.add(BatchNormalization())\n",
    "    model2_2.add(Dense(512, activation='relu'))\n",
    "    model2_2.add(Dropout(0.5))\n",
    "    model2_2.add(BatchNormalization())\n",
    "    model2_2.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model2_2.summary()\n",
    "\n",
    "    model2_2.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "    model3_1 = Sequential()\n",
    "    model3_1.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model3_1.add(Dropout(0.2))\n",
    "    model3_1.add(Dense(512, activation='relu'))\n",
    "    model3_1.add(Dropout(0.2))\n",
    "    model3_1.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model3_1.summary()\n",
    "\n",
    "    model3_1.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_33 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 673,802\n",
      "Trainable params: 671,754\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "    model3_2 = Sequential()\n",
    "    model3_2.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model3_2.add(Dropout(0.2))\n",
    "    model3_2.add(BatchNormalization())\n",
    "    model3_2.add(Dense(512, activation='relu'))\n",
    "    model3_2.add(Dropout(0.2))\n",
    "    model3_2.add(BatchNormalization())\n",
    "    model3_2.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model3_2.summary()\n",
    "\n",
    "    model3_2.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.9859 - accuracy: 0.2970 - val_loss: 1.2499 - val_accuracy: 0.6512\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.3897 - accuracy: 0.4929 - val_loss: 0.9018 - val_accuracy: 0.6895\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.1611 - accuracy: 0.5704 - val_loss: 0.7840 - val_accuracy: 0.7170\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.0343 - accuracy: 0.6180 - val_loss: 0.7241 - val_accuracy: 0.7377\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.9531 - accuracy: 0.6456 - val_loss: 0.6814 - val_accuracy: 0.7557\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.8955 - accuracy: 0.6672 - val_loss: 0.6520 - val_accuracy: 0.7623\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.8535 - accuracy: 0.6860 - val_loss: 0.6265 - val_accuracy: 0.7732\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.8170 - accuracy: 0.6999 - val_loss: 0.6077 - val_accuracy: 0.7804\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.7929 - accuracy: 0.7096 - val_loss: 0.5907 - val_accuracy: 0.7902\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.7608 - accuracy: 0.7203 - val_loss: 0.5747 - val_accuracy: 0.7929\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.7476 - accuracy: 0.7287 - val_loss: 0.5603 - val_accuracy: 0.8010\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.7283 - accuracy: 0.7377 - val_loss: 0.5486 - val_accuracy: 0.8058\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.7100 - accuracy: 0.7458 - val_loss: 0.5352 - val_accuracy: 0.8125\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.6945 - accuracy: 0.7504 - val_loss: 0.5299 - val_accuracy: 0.8158\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6852 - accuracy: 0.7545 - val_loss: 0.5187 - val_accuracy: 0.8209\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.6779 - accuracy: 0.7577 - val_loss: 0.5158 - val_accuracy: 0.8214\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6572 - accuracy: 0.7659 - val_loss: 0.5039 - val_accuracy: 0.8236\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6531 - accuracy: 0.7691 - val_loss: 0.4980 - val_accuracy: 0.8275\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.6394 - accuracy: 0.7697 - val_loss: 0.4921 - val_accuracy: 0.8301\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6313 - accuracy: 0.7766 - val_loss: 0.4872 - val_accuracy: 0.8304\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6203 - accuracy: 0.7797 - val_loss: 0.4808 - val_accuracy: 0.8307\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.6151 - accuracy: 0.7828 - val_loss: 0.4771 - val_accuracy: 0.8338\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6109 - accuracy: 0.7847 - val_loss: 0.4719 - val_accuracy: 0.8362\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6066 - accuracy: 0.7873 - val_loss: 0.4690 - val_accuracy: 0.8364\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5974 - accuracy: 0.7923 - val_loss: 0.4634 - val_accuracy: 0.8365\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5946 - accuracy: 0.7897 - val_loss: 0.4597 - val_accuracy: 0.8385\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5876 - accuracy: 0.7934 - val_loss: 0.4567 - val_accuracy: 0.8375\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5791 - accuracy: 0.7970 - val_loss: 0.4553 - val_accuracy: 0.8411\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5792 - accuracy: 0.7974 - val_loss: 0.4513 - val_accuracy: 0.8409\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5721 - accuracy: 0.8003 - val_loss: 0.4469 - val_accuracy: 0.8411\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5693 - accuracy: 0.8014 - val_loss: 0.4432 - val_accuracy: 0.8422\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5621 - accuracy: 0.8058 - val_loss: 0.4421 - val_accuracy: 0.8447\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5608 - accuracy: 0.8039 - val_loss: 0.4382 - val_accuracy: 0.8443\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5557 - accuracy: 0.8060 - val_loss: 0.4370 - val_accuracy: 0.8442\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5477 - accuracy: 0.8084 - val_loss: 0.4354 - val_accuracy: 0.8459\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.5454 - accuracy: 0.8097 - val_loss: 0.4315 - val_accuracy: 0.8453\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5451 - accuracy: 0.8080 - val_loss: 0.4311 - val_accuracy: 0.8460\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5402 - accuracy: 0.8097 - val_loss: 0.4299 - val_accuracy: 0.8463\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5390 - accuracy: 0.8124 - val_loss: 0.4297 - val_accuracy: 0.8471\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.5369 - accuracy: 0.8114 - val_loss: 0.4270 - val_accuracy: 0.8496\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.5333 - accuracy: 0.8153 - val_loss: 0.4234 - val_accuracy: 0.8503\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5324 - accuracy: 0.8164 - val_loss: 0.4227 - val_accuracy: 0.8497\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5275 - accuracy: 0.8170 - val_loss: 0.4201 - val_accuracy: 0.8515\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.5248 - accuracy: 0.8160 - val_loss: 0.4202 - val_accuracy: 0.8512\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5208 - accuracy: 0.8181 - val_loss: 0.4180 - val_accuracy: 0.8506\n",
      "Epoch 46/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5150 - accuracy: 0.8208 - val_loss: 0.4169 - val_accuracy: 0.8518\n",
      "Epoch 47/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5148 - accuracy: 0.8185 - val_loss: 0.4128 - val_accuracy: 0.8528\n",
      "Epoch 48/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5121 - accuracy: 0.8203 - val_loss: 0.4134 - val_accuracy: 0.8521\n",
      "Epoch 49/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5139 - accuracy: 0.8211 - val_loss: 0.4105 - val_accuracy: 0.8545\n",
      "Epoch 50/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5067 - accuracy: 0.8258 - val_loss: 0.4117 - val_accuracy: 0.8531\n",
      "Epoch 51/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5072 - accuracy: 0.8233 - val_loss: 0.4097 - val_accuracy: 0.8539\n",
      "Epoch 52/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5087 - accuracy: 0.8236 - val_loss: 0.4084 - val_accuracy: 0.8537\n",
      "Epoch 53/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5006 - accuracy: 0.8253 - val_loss: 0.4079 - val_accuracy: 0.8533\n",
      "Epoch 54/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.5001 - accuracy: 0.8235 - val_loss: 0.4040 - val_accuracy: 0.8548\n",
      "Epoch 55/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5004 - accuracy: 0.8267 - val_loss: 0.4047 - val_accuracy: 0.8566\n",
      "Epoch 56/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4969 - accuracy: 0.8267 - val_loss: 0.4032 - val_accuracy: 0.8584\n",
      "Epoch 57/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4950 - accuracy: 0.8288 - val_loss: 0.3998 - val_accuracy: 0.8581\n",
      "Epoch 58/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4921 - accuracy: 0.8290 - val_loss: 0.3999 - val_accuracy: 0.8589\n",
      "Epoch 59/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4881 - accuracy: 0.8300 - val_loss: 0.3998 - val_accuracy: 0.8588\n",
      "Epoch 60/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.4877 - accuracy: 0.8295 - val_loss: 0.3972 - val_accuracy: 0.8593\n"
     ]
    }
   ],
   "source": [
    "history1_1 = model1_1.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0238 - accuracy: 0.3215 - val_loss: 1.0047 - val_accuracy: 0.7088\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.2973 - accuracy: 0.5310 - val_loss: 0.7790 - val_accuracy: 0.7422\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.0758 - accuracy: 0.6057 - val_loss: 0.7130 - val_accuracy: 0.7467\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.9667 - accuracy: 0.6446 - val_loss: 0.6667 - val_accuracy: 0.7635\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.8976 - accuracy: 0.6689 - val_loss: 0.6453 - val_accuracy: 0.7741\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.8478 - accuracy: 0.6900 - val_loss: 0.6196 - val_accuracy: 0.7791\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.8142 - accuracy: 0.7042 - val_loss: 0.6025 - val_accuracy: 0.7862\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.7906 - accuracy: 0.7147 - val_loss: 0.5899 - val_accuracy: 0.7909\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.7633 - accuracy: 0.7223 - val_loss: 0.5758 - val_accuracy: 0.7978\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.7397 - accuracy: 0.7336 - val_loss: 0.5666 - val_accuracy: 0.8010\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.7248 - accuracy: 0.7365 - val_loss: 0.5523 - val_accuracy: 0.8045\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.7061 - accuracy: 0.7468 - val_loss: 0.5453 - val_accuracy: 0.8081\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.6982 - accuracy: 0.7512 - val_loss: 0.5304 - val_accuracy: 0.8129\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.6896 - accuracy: 0.7538 - val_loss: 0.5262 - val_accuracy: 0.8168\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.6785 - accuracy: 0.7576 - val_loss: 0.5228 - val_accuracy: 0.8171\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.6642 - accuracy: 0.7625 - val_loss: 0.5163 - val_accuracy: 0.8202\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.6583 - accuracy: 0.7691 - val_loss: 0.5079 - val_accuracy: 0.8239\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.6464 - accuracy: 0.7706 - val_loss: 0.4996 - val_accuracy: 0.8273\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.6464 - accuracy: 0.7727 - val_loss: 0.5004 - val_accuracy: 0.8278\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.6313 - accuracy: 0.7782 - val_loss: 0.4945 - val_accuracy: 0.8300\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.6231 - accuracy: 0.7801 - val_loss: 0.4874 - val_accuracy: 0.8305\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.6162 - accuracy: 0.7826 - val_loss: 0.4854 - val_accuracy: 0.8306\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.6144 - accuracy: 0.7860 - val_loss: 0.4770 - val_accuracy: 0.8351\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.6081 - accuracy: 0.7852 - val_loss: 0.4773 - val_accuracy: 0.8357\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5989 - accuracy: 0.7887 - val_loss: 0.4716 - val_accuracy: 0.8378\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5971 - accuracy: 0.7927 - val_loss: 0.4642 - val_accuracy: 0.8391\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5927 - accuracy: 0.7933 - val_loss: 0.4624 - val_accuracy: 0.8410\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5847 - accuracy: 0.7954 - val_loss: 0.4591 - val_accuracy: 0.8414\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5784 - accuracy: 0.7975 - val_loss: 0.4544 - val_accuracy: 0.8419\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5735 - accuracy: 0.7986 - val_loss: 0.4538 - val_accuracy: 0.8417\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5790 - accuracy: 0.7989 - val_loss: 0.4467 - val_accuracy: 0.8443\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5698 - accuracy: 0.8003 - val_loss: 0.4447 - val_accuracy: 0.8436\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5641 - accuracy: 0.8029 - val_loss: 0.4451 - val_accuracy: 0.8445\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5615 - accuracy: 0.8018 - val_loss: 0.4450 - val_accuracy: 0.8461\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5577 - accuracy: 0.8050 - val_loss: 0.4411 - val_accuracy: 0.8463\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5542 - accuracy: 0.8053 - val_loss: 0.4378 - val_accuracy: 0.8472\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5507 - accuracy: 0.8074 - val_loss: 0.4367 - val_accuracy: 0.8470\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5473 - accuracy: 0.8079 - val_loss: 0.4358 - val_accuracy: 0.8478\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5437 - accuracy: 0.8101 - val_loss: 0.4340 - val_accuracy: 0.8471\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5415 - accuracy: 0.8136 - val_loss: 0.4319 - val_accuracy: 0.8492\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5357 - accuracy: 0.8130 - val_loss: 0.4290 - val_accuracy: 0.8493\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5295 - accuracy: 0.8156 - val_loss: 0.4237 - val_accuracy: 0.8522\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5376 - accuracy: 0.8137 - val_loss: 0.4251 - val_accuracy: 0.8510\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5325 - accuracy: 0.8153 - val_loss: 0.4275 - val_accuracy: 0.8500\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5353 - accuracy: 0.8117 - val_loss: 0.4239 - val_accuracy: 0.8508\n",
      "Epoch 46/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5291 - accuracy: 0.8142 - val_loss: 0.4280 - val_accuracy: 0.8482\n",
      "Epoch 47/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5268 - accuracy: 0.8146 - val_loss: 0.4198 - val_accuracy: 0.8533\n",
      "Epoch 48/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5205 - accuracy: 0.8194 - val_loss: 0.4189 - val_accuracy: 0.8535\n",
      "Epoch 49/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5217 - accuracy: 0.8174 - val_loss: 0.4208 - val_accuracy: 0.8520\n",
      "Epoch 50/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5184 - accuracy: 0.8194 - val_loss: 0.4213 - val_accuracy: 0.8514\n",
      "Epoch 51/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5188 - accuracy: 0.8203 - val_loss: 0.4176 - val_accuracy: 0.8535\n",
      "Epoch 52/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5141 - accuracy: 0.8214 - val_loss: 0.4159 - val_accuracy: 0.8553\n",
      "Epoch 53/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5099 - accuracy: 0.8212 - val_loss: 0.4098 - val_accuracy: 0.8549\n",
      "Epoch 54/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5153 - accuracy: 0.8188 - val_loss: 0.4106 - val_accuracy: 0.8561\n",
      "Epoch 55/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5119 - accuracy: 0.8209 - val_loss: 0.4118 - val_accuracy: 0.8533\n",
      "Epoch 56/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5054 - accuracy: 0.8246 - val_loss: 0.4095 - val_accuracy: 0.8575\n",
      "Epoch 57/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5055 - accuracy: 0.8231 - val_loss: 0.4115 - val_accuracy: 0.8565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5082 - accuracy: 0.8226 - val_loss: 0.4072 - val_accuracy: 0.8558\n",
      "Epoch 59/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5007 - accuracy: 0.8267 - val_loss: 0.4084 - val_accuracy: 0.8583\n",
      "Epoch 60/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.4987 - accuracy: 0.8251 - val_loss: 0.4069 - val_accuracy: 0.8568\n"
     ]
    }
   ],
   "source": [
    "history1_2 = model1_2.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.4087 - accuracy: 0.5072 - val_loss: 0.8207 - val_accuracy: 0.7198\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.9034 - accuracy: 0.6818 - val_loss: 0.6809 - val_accuracy: 0.7568\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.7810 - accuracy: 0.7254 - val_loss: 0.6170 - val_accuracy: 0.7846\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.7135 - accuracy: 0.7484 - val_loss: 0.5797 - val_accuracy: 0.7988\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.6665 - accuracy: 0.7651 - val_loss: 0.5459 - val_accuracy: 0.8106\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.6306 - accuracy: 0.7826 - val_loss: 0.5266 - val_accuracy: 0.8142\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6044 - accuracy: 0.7904 - val_loss: 0.5061 - val_accuracy: 0.8233\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5872 - accuracy: 0.7972 - val_loss: 0.4937 - val_accuracy: 0.8266\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5640 - accuracy: 0.8036 - val_loss: 0.4822 - val_accuracy: 0.8287\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5499 - accuracy: 0.8092 - val_loss: 0.4715 - val_accuracy: 0.8322\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5344 - accuracy: 0.8132 - val_loss: 0.4615 - val_accuracy: 0.8367\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5190 - accuracy: 0.8185 - val_loss: 0.4529 - val_accuracy: 0.8387\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5128 - accuracy: 0.8198 - val_loss: 0.4476 - val_accuracy: 0.8393\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5014 - accuracy: 0.8240 - val_loss: 0.4395 - val_accuracy: 0.8426\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4930 - accuracy: 0.8280 - val_loss: 0.4320 - val_accuracy: 0.8440\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.4861 - accuracy: 0.8298 - val_loss: 0.4300 - val_accuracy: 0.8458\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4793 - accuracy: 0.8317 - val_loss: 0.4237 - val_accuracy: 0.8457\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4723 - accuracy: 0.8331 - val_loss: 0.4202 - val_accuracy: 0.8504\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4676 - accuracy: 0.8355 - val_loss: 0.4140 - val_accuracy: 0.8519\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4626 - accuracy: 0.8374 - val_loss: 0.4085 - val_accuracy: 0.8529\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4553 - accuracy: 0.8394 - val_loss: 0.4077 - val_accuracy: 0.8543\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.4518 - accuracy: 0.8404 - val_loss: 0.4044 - val_accuracy: 0.8542\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4443 - accuracy: 0.8447 - val_loss: 0.4006 - val_accuracy: 0.8561\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4421 - accuracy: 0.8443 - val_loss: 0.3969 - val_accuracy: 0.8565\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4372 - accuracy: 0.8450 - val_loss: 0.3940 - val_accuracy: 0.8594\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4311 - accuracy: 0.8468 - val_loss: 0.3905 - val_accuracy: 0.8597\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4284 - accuracy: 0.8481 - val_loss: 0.3883 - val_accuracy: 0.8618\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4256 - accuracy: 0.8487 - val_loss: 0.3851 - val_accuracy: 0.8609\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4233 - accuracy: 0.8507 - val_loss: 0.3823 - val_accuracy: 0.8627\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4196 - accuracy: 0.8510 - val_loss: 0.3822 - val_accuracy: 0.8634\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4153 - accuracy: 0.8538 - val_loss: 0.3785 - val_accuracy: 0.8648\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4128 - accuracy: 0.8536 - val_loss: 0.3777 - val_accuracy: 0.8643\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4059 - accuracy: 0.8556 - val_loss: 0.3751 - val_accuracy: 0.8651\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4081 - accuracy: 0.8558 - val_loss: 0.3746 - val_accuracy: 0.8644\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4018 - accuracy: 0.8562 - val_loss: 0.3728 - val_accuracy: 0.8662\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3995 - accuracy: 0.8582 - val_loss: 0.3682 - val_accuracy: 0.8683\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3992 - accuracy: 0.8604 - val_loss: 0.3675 - val_accuracy: 0.8679\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3957 - accuracy: 0.8593 - val_loss: 0.3657 - val_accuracy: 0.8679\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3950 - accuracy: 0.8600 - val_loss: 0.3646 - val_accuracy: 0.8687\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3907 - accuracy: 0.8612 - val_loss: 0.3618 - val_accuracy: 0.8715\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3886 - accuracy: 0.8603 - val_loss: 0.3620 - val_accuracy: 0.8692\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3852 - accuracy: 0.8626 - val_loss: 0.3602 - val_accuracy: 0.8696\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3837 - accuracy: 0.8626 - val_loss: 0.3571 - val_accuracy: 0.8721\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3818 - accuracy: 0.8641 - val_loss: 0.3560 - val_accuracy: 0.8717\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3802 - accuracy: 0.8636 - val_loss: 0.3564 - val_accuracy: 0.8717\n",
      "Epoch 46/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3759 - accuracy: 0.8673 - val_loss: 0.3534 - val_accuracy: 0.8737\n",
      "Epoch 47/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3770 - accuracy: 0.8669 - val_loss: 0.3534 - val_accuracy: 0.8732\n",
      "Epoch 48/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3748 - accuracy: 0.8675 - val_loss: 0.3513 - val_accuracy: 0.8729\n",
      "Epoch 49/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3729 - accuracy: 0.8698 - val_loss: 0.3503 - val_accuracy: 0.8747\n",
      "Epoch 50/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3690 - accuracy: 0.8686 - val_loss: 0.3517 - val_accuracy: 0.8724\n",
      "Epoch 51/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3677 - accuracy: 0.8683 - val_loss: 0.3474 - val_accuracy: 0.8754\n",
      "Epoch 52/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.3643 - accuracy: 0.8698 - val_loss: 0.3468 - val_accuracy: 0.8765\n",
      "Epoch 53/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3639 - accuracy: 0.8692 - val_loss: 0.3476 - val_accuracy: 0.8741\n",
      "Epoch 54/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3617 - accuracy: 0.8694 - val_loss: 0.3452 - val_accuracy: 0.8768\n",
      "Epoch 55/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3593 - accuracy: 0.8731 - val_loss: 0.3435 - val_accuracy: 0.8756\n",
      "Epoch 56/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3565 - accuracy: 0.8730 - val_loss: 0.3427 - val_accuracy: 0.8771\n",
      "Epoch 57/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3589 - accuracy: 0.8710 - val_loss: 0.3411 - val_accuracy: 0.8783\n",
      "Epoch 58/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3548 - accuracy: 0.8737 - val_loss: 0.3409 - val_accuracy: 0.8782\n",
      "Epoch 59/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3552 - accuracy: 0.8727 - val_loss: 0.3403 - val_accuracy: 0.8786\n",
      "Epoch 60/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3546 - accuracy: 0.8745 - val_loss: 0.3389 - val_accuracy: 0.8800\n"
     ]
    }
   ],
   "source": [
    "history2_1 = model2_1.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.0762 - accuracy: 0.6294 - val_loss: 0.5882 - val_accuracy: 0.7991\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.6925 - accuracy: 0.7548 - val_loss: 0.4814 - val_accuracy: 0.8256\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.6116 - accuracy: 0.7830 - val_loss: 0.4483 - val_accuracy: 0.8373\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5706 - accuracy: 0.7973 - val_loss: 0.4313 - val_accuracy: 0.8438\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5374 - accuracy: 0.8089 - val_loss: 0.4157 - val_accuracy: 0.8487\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5141 - accuracy: 0.8160 - val_loss: 0.4093 - val_accuracy: 0.8513\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4933 - accuracy: 0.8224 - val_loss: 0.3987 - val_accuracy: 0.8548\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4825 - accuracy: 0.8267 - val_loss: 0.3946 - val_accuracy: 0.8574\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4629 - accuracy: 0.8353 - val_loss: 0.3844 - val_accuracy: 0.8608\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4589 - accuracy: 0.8369 - val_loss: 0.3775 - val_accuracy: 0.8621\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4479 - accuracy: 0.8387 - val_loss: 0.3754 - val_accuracy: 0.8640\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4389 - accuracy: 0.8440 - val_loss: 0.3687 - val_accuracy: 0.8643\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4313 - accuracy: 0.8444 - val_loss: 0.3625 - val_accuracy: 0.8687\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4225 - accuracy: 0.8486 - val_loss: 0.3685 - val_accuracy: 0.8680\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4193 - accuracy: 0.8511 - val_loss: 0.3622 - val_accuracy: 0.8683\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4146 - accuracy: 0.8512 - val_loss: 0.3612 - val_accuracy: 0.8693\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4067 - accuracy: 0.8521 - val_loss: 0.3566 - val_accuracy: 0.8702\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4018 - accuracy: 0.8544 - val_loss: 0.3529 - val_accuracy: 0.8725\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3987 - accuracy: 0.8562 - val_loss: 0.3500 - val_accuracy: 0.8732\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3915 - accuracy: 0.8598 - val_loss: 0.3495 - val_accuracy: 0.8720\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3883 - accuracy: 0.8603 - val_loss: 0.3460 - val_accuracy: 0.8763\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.3833 - accuracy: 0.8626 - val_loss: 0.3468 - val_accuracy: 0.8752\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.3834 - accuracy: 0.8625 - val_loss: 0.3459 - val_accuracy: 0.8765\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3731 - accuracy: 0.8650 - val_loss: 0.3407 - val_accuracy: 0.8777\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3735 - accuracy: 0.8655 - val_loss: 0.3384 - val_accuracy: 0.8789\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3677 - accuracy: 0.8664 - val_loss: 0.3353 - val_accuracy: 0.8803\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3653 - accuracy: 0.8680 - val_loss: 0.3338 - val_accuracy: 0.8807\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3620 - accuracy: 0.8696 - val_loss: 0.3308 - val_accuracy: 0.8810\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3580 - accuracy: 0.8717 - val_loss: 0.3333 - val_accuracy: 0.8798\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3543 - accuracy: 0.8716 - val_loss: 0.3302 - val_accuracy: 0.8802\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3520 - accuracy: 0.8716 - val_loss: 0.3283 - val_accuracy: 0.8804\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3515 - accuracy: 0.8726 - val_loss: 0.3296 - val_accuracy: 0.8806\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.3459 - accuracy: 0.8746 - val_loss: 0.3271 - val_accuracy: 0.8824\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3428 - accuracy: 0.8748 - val_loss: 0.3243 - val_accuracy: 0.8838\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3436 - accuracy: 0.8749 - val_loss: 0.3230 - val_accuracy: 0.8829\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3379 - accuracy: 0.8757 - val_loss: 0.3223 - val_accuracy: 0.8841\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3379 - accuracy: 0.8770 - val_loss: 0.3212 - val_accuracy: 0.8828\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3344 - accuracy: 0.8776 - val_loss: 0.3174 - val_accuracy: 0.8842\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3304 - accuracy: 0.8800 - val_loss: 0.3236 - val_accuracy: 0.8834\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3308 - accuracy: 0.8794 - val_loss: 0.3195 - val_accuracy: 0.8843\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3278 - accuracy: 0.8813 - val_loss: 0.3203 - val_accuracy: 0.8849\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3298 - accuracy: 0.8797 - val_loss: 0.3213 - val_accuracy: 0.8821\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.3257 - accuracy: 0.8821 - val_loss: 0.3154 - val_accuracy: 0.8850\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.3246 - accuracy: 0.8819 - val_loss: 0.3184 - val_accuracy: 0.8845\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3184 - accuracy: 0.8830 - val_loss: 0.3184 - val_accuracy: 0.8842\n",
      "Epoch 46/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3187 - accuracy: 0.8826 - val_loss: 0.3175 - val_accuracy: 0.8852\n",
      "Epoch 47/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.3135 - accuracy: 0.8853 - val_loss: 0.3147 - val_accuracy: 0.8874\n",
      "Epoch 48/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.3112 - accuracy: 0.8869 - val_loss: 0.3169 - val_accuracy: 0.8863\n",
      "Epoch 49/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.3108 - accuracy: 0.8856 - val_loss: 0.3123 - val_accuracy: 0.8871\n",
      "Epoch 50/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.3129 - accuracy: 0.8874 - val_loss: 0.3150 - val_accuracy: 0.8844\n",
      "Epoch 51/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.3065 - accuracy: 0.8892 - val_loss: 0.3122 - val_accuracy: 0.8878\n",
      "Epoch 52/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.3084 - accuracy: 0.8859 - val_loss: 0.3092 - val_accuracy: 0.8890\n",
      "Epoch 53/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3024 - accuracy: 0.8892 - val_loss: 0.3204 - val_accuracy: 0.8843\n",
      "Epoch 54/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3028 - accuracy: 0.8895 - val_loss: 0.3093 - val_accuracy: 0.8886\n",
      "Epoch 55/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.3012 - accuracy: 0.8885 - val_loss: 0.3110 - val_accuracy: 0.8882\n",
      "Epoch 56/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2966 - accuracy: 0.8916 - val_loss: 0.3095 - val_accuracy: 0.8875\n",
      "Epoch 57/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2967 - accuracy: 0.8908 - val_loss: 0.3054 - val_accuracy: 0.8890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2947 - accuracy: 0.8918 - val_loss: 0.3065 - val_accuracy: 0.8884\n",
      "Epoch 59/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2897 - accuracy: 0.8928 - val_loss: 0.3056 - val_accuracy: 0.8899\n",
      "Epoch 60/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2956 - accuracy: 0.8913 - val_loss: 0.3050 - val_accuracy: 0.8907\n"
     ]
    }
   ],
   "source": [
    "history2_2 = model2_2.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 1.2041 - accuracy: 0.6135 - val_loss: 0.7423 - val_accuracy: 0.7603\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.7479 - accuracy: 0.7492 - val_loss: 0.6205 - val_accuracy: 0.7883\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6475 - accuracy: 0.7823 - val_loss: 0.5593 - val_accuracy: 0.8113\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5976 - accuracy: 0.7968 - val_loss: 0.5264 - val_accuracy: 0.8215\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5621 - accuracy: 0.8081 - val_loss: 0.5052 - val_accuracy: 0.8255\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5373 - accuracy: 0.8160 - val_loss: 0.4862 - val_accuracy: 0.8319\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.5168 - accuracy: 0.8224 - val_loss: 0.4721 - val_accuracy: 0.8383\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5018 - accuracy: 0.8264 - val_loss: 0.4625 - val_accuracy: 0.8401\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.4871 - accuracy: 0.8305 - val_loss: 0.4568 - val_accuracy: 0.8402\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4773 - accuracy: 0.8361 - val_loss: 0.4454 - val_accuracy: 0.8443\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4654 - accuracy: 0.8393 - val_loss: 0.4418 - val_accuracy: 0.8455\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4580 - accuracy: 0.8416 - val_loss: 0.4302 - val_accuracy: 0.8485\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4484 - accuracy: 0.8433 - val_loss: 0.4275 - val_accuracy: 0.8483\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4406 - accuracy: 0.8472 - val_loss: 0.4184 - val_accuracy: 0.8530\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4346 - accuracy: 0.8475 - val_loss: 0.4109 - val_accuracy: 0.8561\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4254 - accuracy: 0.8524 - val_loss: 0.4127 - val_accuracy: 0.8534\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4192 - accuracy: 0.8536 - val_loss: 0.4062 - val_accuracy: 0.8553\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4147 - accuracy: 0.8546 - val_loss: 0.4007 - val_accuracy: 0.8585\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4105 - accuracy: 0.8562 - val_loss: 0.3939 - val_accuracy: 0.8604\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4053 - accuracy: 0.8583 - val_loss: 0.3912 - val_accuracy: 0.8617\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4007 - accuracy: 0.8585 - val_loss: 0.3876 - val_accuracy: 0.8625\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3942 - accuracy: 0.8614 - val_loss: 0.3890 - val_accuracy: 0.8629\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3913 - accuracy: 0.8616 - val_loss: 0.3821 - val_accuracy: 0.8648\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3865 - accuracy: 0.8634 - val_loss: 0.3772 - val_accuracy: 0.8661\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3843 - accuracy: 0.8641 - val_loss: 0.3746 - val_accuracy: 0.8668\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3794 - accuracy: 0.8668 - val_loss: 0.3718 - val_accuracy: 0.8681\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3760 - accuracy: 0.8672 - val_loss: 0.3708 - val_accuracy: 0.8692\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3721 - accuracy: 0.8685 - val_loss: 0.3689 - val_accuracy: 0.8687\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3698 - accuracy: 0.8694 - val_loss: 0.3646 - val_accuracy: 0.8686\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3661 - accuracy: 0.8697 - val_loss: 0.3643 - val_accuracy: 0.8684\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3628 - accuracy: 0.8712 - val_loss: 0.3612 - val_accuracy: 0.8705\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3587 - accuracy: 0.8737 - val_loss: 0.3600 - val_accuracy: 0.8718\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3600 - accuracy: 0.8717 - val_loss: 0.3564 - val_accuracy: 0.8718\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3559 - accuracy: 0.8752 - val_loss: 0.3554 - val_accuracy: 0.8727\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3518 - accuracy: 0.8756 - val_loss: 0.3553 - val_accuracy: 0.8712\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3504 - accuracy: 0.8761 - val_loss: 0.3511 - val_accuracy: 0.8753\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3468 - accuracy: 0.8771 - val_loss: 0.3500 - val_accuracy: 0.8729\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3438 - accuracy: 0.8768 - val_loss: 0.3478 - val_accuracy: 0.8744\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3422 - accuracy: 0.8785 - val_loss: 0.3468 - val_accuracy: 0.8776\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3400 - accuracy: 0.8795 - val_loss: 0.3454 - val_accuracy: 0.8759\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3363 - accuracy: 0.8799 - val_loss: 0.3461 - val_accuracy: 0.8752\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3366 - accuracy: 0.8803 - val_loss: 0.3424 - val_accuracy: 0.8768\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3302 - accuracy: 0.8816 - val_loss: 0.3422 - val_accuracy: 0.8765\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3327 - accuracy: 0.8823 - val_loss: 0.3381 - val_accuracy: 0.8794\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3299 - accuracy: 0.8821 - val_loss: 0.3395 - val_accuracy: 0.8782\n",
      "Epoch 46/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3268 - accuracy: 0.8823 - val_loss: 0.3356 - val_accuracy: 0.8800\n",
      "Epoch 47/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3232 - accuracy: 0.8835 - val_loss: 0.3360 - val_accuracy: 0.8788\n",
      "Epoch 48/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.3225 - accuracy: 0.8842 - val_loss: 0.3357 - val_accuracy: 0.8799\n",
      "Epoch 49/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3213 - accuracy: 0.8847 - val_loss: 0.3322 - val_accuracy: 0.8809\n",
      "Epoch 50/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3172 - accuracy: 0.8871 - val_loss: 0.3368 - val_accuracy: 0.8812\n",
      "Epoch 51/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3163 - accuracy: 0.8865 - val_loss: 0.3290 - val_accuracy: 0.8828\n",
      "Epoch 52/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3144 - accuracy: 0.8875 - val_loss: 0.3292 - val_accuracy: 0.8815\n",
      "Epoch 53/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3135 - accuracy: 0.8882 - val_loss: 0.3307 - val_accuracy: 0.8815\n",
      "Epoch 54/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3120 - accuracy: 0.8883 - val_loss: 0.3268 - val_accuracy: 0.8831\n",
      "Epoch 55/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.3105 - accuracy: 0.8898 - val_loss: 0.3276 - val_accuracy: 0.8837\n",
      "Epoch 56/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3086 - accuracy: 0.8901 - val_loss: 0.3260 - val_accuracy: 0.8829\n",
      "Epoch 57/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3060 - accuracy: 0.8903 - val_loss: 0.3231 - val_accuracy: 0.8826\n",
      "Epoch 58/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3031 - accuracy: 0.8923 - val_loss: 0.3221 - val_accuracy: 0.8850\n",
      "Epoch 59/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3040 - accuracy: 0.8907 - val_loss: 0.3222 - val_accuracy: 0.8848\n",
      "Epoch 60/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3003 - accuracy: 0.8926 - val_loss: 0.3220 - val_accuracy: 0.8836\n"
     ]
    }
   ],
   "source": [
    "history3_1 = model3_1.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.7353 - accuracy: 0.7451 - val_loss: 0.5036 - val_accuracy: 0.8258\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5155 - accuracy: 0.8184 - val_loss: 0.4163 - val_accuracy: 0.8515\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4580 - accuracy: 0.8363 - val_loss: 0.3880 - val_accuracy: 0.8602\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4308 - accuracy: 0.8462 - val_loss: 0.3751 - val_accuracy: 0.8637\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4072 - accuracy: 0.8543 - val_loss: 0.3619 - val_accuracy: 0.8707\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3905 - accuracy: 0.8594 - val_loss: 0.3583 - val_accuracy: 0.8696\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3746 - accuracy: 0.8643 - val_loss: 0.3504 - val_accuracy: 0.8733\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3629 - accuracy: 0.8684 - val_loss: 0.3488 - val_accuracy: 0.8744\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3506 - accuracy: 0.8736 - val_loss: 0.3372 - val_accuracy: 0.8758\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3384 - accuracy: 0.8780 - val_loss: 0.3325 - val_accuracy: 0.8791\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3325 - accuracy: 0.8807 - val_loss: 0.3313 - val_accuracy: 0.8791\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3232 - accuracy: 0.8824 - val_loss: 0.3290 - val_accuracy: 0.8789\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3189 - accuracy: 0.8844 - val_loss: 0.3237 - val_accuracy: 0.8821\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3096 - accuracy: 0.8876 - val_loss: 0.3219 - val_accuracy: 0.8828\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3011 - accuracy: 0.8908 - val_loss: 0.3180 - val_accuracy: 0.8839\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2994 - accuracy: 0.8906 - val_loss: 0.3155 - val_accuracy: 0.8846\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2944 - accuracy: 0.8915 - val_loss: 0.3174 - val_accuracy: 0.8827\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2841 - accuracy: 0.8959 - val_loss: 0.3149 - val_accuracy: 0.8845\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2814 - accuracy: 0.8956 - val_loss: 0.3109 - val_accuracy: 0.8857\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2749 - accuracy: 0.8996 - val_loss: 0.3107 - val_accuracy: 0.8865\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2702 - accuracy: 0.9001 - val_loss: 0.3102 - val_accuracy: 0.8866\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2663 - accuracy: 0.9020 - val_loss: 0.3180 - val_accuracy: 0.8827\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2611 - accuracy: 0.9036 - val_loss: 0.3056 - val_accuracy: 0.8882\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2569 - accuracy: 0.9047 - val_loss: 0.3086 - val_accuracy: 0.8869\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2539 - accuracy: 0.9069 - val_loss: 0.3084 - val_accuracy: 0.8880\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2508 - accuracy: 0.9079 - val_loss: 0.3059 - val_accuracy: 0.8900\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2454 - accuracy: 0.9104 - val_loss: 0.3053 - val_accuracy: 0.8917\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2407 - accuracy: 0.9114 - val_loss: 0.3062 - val_accuracy: 0.8878\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2382 - accuracy: 0.9113 - val_loss: 0.3053 - val_accuracy: 0.8892\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2344 - accuracy: 0.9131 - val_loss: 0.2988 - val_accuracy: 0.8917\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2317 - accuracy: 0.9134 - val_loss: 0.3061 - val_accuracy: 0.8901\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2275 - accuracy: 0.9150 - val_loss: 0.3017 - val_accuracy: 0.8950\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2230 - accuracy: 0.9186 - val_loss: 0.3012 - val_accuracy: 0.8916\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2206 - accuracy: 0.9199 - val_loss: 0.3083 - val_accuracy: 0.8911\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2215 - accuracy: 0.9176 - val_loss: 0.3017 - val_accuracy: 0.8922\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2185 - accuracy: 0.9196 - val_loss: 0.3001 - val_accuracy: 0.8932\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2100 - accuracy: 0.9218 - val_loss: 0.3019 - val_accuracy: 0.8917\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2101 - accuracy: 0.9208 - val_loss: 0.3036 - val_accuracy: 0.8923\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2065 - accuracy: 0.9247 - val_loss: 0.3094 - val_accuracy: 0.8910\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2032 - accuracy: 0.9242 - val_loss: 0.3023 - val_accuracy: 0.8935\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1979 - accuracy: 0.9270 - val_loss: 0.3002 - val_accuracy: 0.8953\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1986 - accuracy: 0.9259 - val_loss: 0.3046 - val_accuracy: 0.8947\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1939 - accuracy: 0.9270 - val_loss: 0.3109 - val_accuracy: 0.8902\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1933 - accuracy: 0.9275 - val_loss: 0.3069 - val_accuracy: 0.8928\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1879 - accuracy: 0.9301 - val_loss: 0.3171 - val_accuracy: 0.8899\n",
      "Epoch 46/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1864 - accuracy: 0.9304 - val_loss: 0.3091 - val_accuracy: 0.8932\n",
      "Epoch 47/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1839 - accuracy: 0.9314 - val_loss: 0.3122 - val_accuracy: 0.8923\n",
      "Epoch 48/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1831 - accuracy: 0.9322 - val_loss: 0.3153 - val_accuracy: 0.8913\n",
      "Epoch 49/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1773 - accuracy: 0.9337 - val_loss: 0.3088 - val_accuracy: 0.8936\n",
      "Epoch 50/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1756 - accuracy: 0.9348 - val_loss: 0.3156 - val_accuracy: 0.8923\n",
      "Epoch 51/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1764 - accuracy: 0.9356 - val_loss: 0.3107 - val_accuracy: 0.8939\n",
      "Epoch 52/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.1746 - accuracy: 0.9348 - val_loss: 0.3094 - val_accuracy: 0.8945\n",
      "Epoch 53/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.1693 - accuracy: 0.9384 - val_loss: 0.3208 - val_accuracy: 0.8926\n",
      "Epoch 54/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1683 - accuracy: 0.9376 - val_loss: 0.3088 - val_accuracy: 0.8951\n",
      "Epoch 55/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1664 - accuracy: 0.9375 - val_loss: 0.3134 - val_accuracy: 0.8978\n",
      "Epoch 56/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1645 - accuracy: 0.9393 - val_loss: 0.3106 - val_accuracy: 0.8966\n",
      "Epoch 57/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1631 - accuracy: 0.9395 - val_loss: 0.3110 - val_accuracy: 0.8972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1623 - accuracy: 0.9409 - val_loss: 0.3113 - val_accuracy: 0.8972\n",
      "Epoch 59/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1557 - accuracy: 0.9434 - val_loss: 0.3153 - val_accuracy: 0.8949\n",
      "Epoch 60/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1567 - accuracy: 0.9417 - val_loss: 0.3231 - val_accuracy: 0.8931\n"
     ]
    }
   ],
   "source": [
    "history3_2 = model3_2.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.4215 - accuracy: 0.8476\n",
      "Dropout Rate : 0.8\n",
      "0.847599983215332\n",
      "Accuracy: 84.76%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics1_1 = model1_1.evaluate(x_test, y_test) #returns loss and accuracy\n",
    "print(\"Dropout Rate : 0.8\")\n",
    "print(metrics1_1[1])\n",
    "print(f'Accuracy: {metrics1_1[1]*100:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.4293 - accuracy: 0.8489\n",
      "Dropout Rate : 0.8 with batchnormalization\n",
      "0.8489000201225281\n",
      "Accuracy: 84.89%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics1_2 = model1_2.evaluate(x_test, y_test) #returns loss and accuracy\n",
    "print(\"Dropout Rate : 0.8 with batchnormalization\")\n",
    "print(metrics1_2[1])\n",
    "print(f'Accuracy: {metrics1_2[1]*100:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3624 - accuracy: 0.8701\n",
      "Dropout Rate : 0.5\n",
      "0.8701000213623047\n",
      "Accuracy: 87.01%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics2_1 = model2_1.evaluate(x_test, y_test) #returns loss and accuracy\n",
    "print(\"Dropout Rate : 0.5\")\n",
    "print(metrics2_1[1])\n",
    "print(f'Accuracy: {metrics2_1[1]*100:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8848\n",
      "Dropout Rate : 0.5 with batchnormalization\n",
      "0.8848000168800354\n",
      "Accuracy: 88.48%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics2_2 = model2_2.evaluate(x_test, y_test) #returns loss and accuracy\n",
    "print(\"Dropout Rate : 0.5 with batchnormalization\")\n",
    "print(metrics2_2[1])\n",
    "print(f'Accuracy: {metrics2_2[1]*100:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3481 - accuracy: 0.8767\n",
      "Dropout Rate : 0.2\n",
      "0.8766999840736389\n",
      "Accuracy: 87.67%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics3_1 = model3_1.evaluate(x_test, y_test) #returns loss and accuracy\n",
    "print(\"Dropout Rate : 0.2\")\n",
    "print(metrics3_1[1])\n",
    "print(f'Accuracy: {metrics3_1[1]*100:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3431 - accuracy: 0.8899\n",
      "Dropout Rate : 0.2 with batchnormalization\n",
      "0.8899000287055969\n",
      "Accuracy: 88.99%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics3_2 = model3_2.evaluate(x_test, y_test) #returns loss and accuracy\n",
    "print(\"Dropout Rate : 0.2 with batchnormalization\")\n",
    "print(metrics3_2[1])\n",
    "print(f'Accuracy: {metrics3_2[1]*100:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 분석결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "저는 dropout rate를 0.8, 0.5, 0.2순으로 학습을 수행해보았습니다.\n",
    "\n",
    "다음은 그 결과로 나온 정확도입니다.\n",
    "\n",
    "-Dropout Rate 0.2    / with BatchNormalization\n",
    "\n",
    "Accuracy: 87.67%     / Accuracy: 88.99%\n",
    "\n",
    "-Dropout Rate 0.5    / with BatchNormalization\n",
    "\n",
    "Accuracy: 87.01%     / Accuracy: 88.48%\n",
    "\n",
    "-Dropout Rate 0.8    / with BatchNormalization\n",
    "\n",
    "Accuracy: 84.76%     / Accuracy: 84.89%\n",
    "\n",
    "Dropout Rate이 각각 0.2, 0.5, 0.8로 dropout rate이 증가할수록 정확도는\n",
    "\n",
    "점점 감소하는 것을 확인할 수 있다. 이는 drop하는 neuron의 수가 많아질수록\n",
    "\n",
    "정확도는 떨어지지만 overfitting은 피할 수 있다는 것을 확인할 수 있다.\n",
    "\n",
    "각각의 Dropout에서 Batch Normalization을 적용한 경우 dropout rate가 0.2, 0.5, 0.8인 경우\n",
    "\n",
    "정확도가 조금 증가한 것을 볼 수 있는데 이는 batch normalization과 dropout이 비슷한 역할을 하기 때문에\n",
    "\n",
    "정확도가 조금 증가한 것으로 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
